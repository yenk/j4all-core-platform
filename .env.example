# LumiLens AI Platform Environment Configuration Template
# Copy this file to .env and fill in your actual values
# NEVER commit .env files with real secrets to git!

# OpenAI Configuration (REQUIRED)
OPENAI_API_KEY=your_openai_api_key_here

# Environment Settings
ENVIRONMENT=development
DEBUG=true

# Server Configuration
HOST=0.0.0.0
PORT=8000

# Security (Generate a strong random string)
# LumiLens AI Platform Environment Configuration Template
# Copy this file to .env and fill in your actual values
# NEVER commit .env files with real secrets to git!

# OpenAI Configuration (REQUIRED)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Environment Settings
ENVIRONMENT=development  # Use "production" for deployment
DEBUG=true               # Set to false in production

# Server Configuration
HOST=0.0.0.0
PORT=8000

# Security (Change in production - use a long random string)
SECRET_KEY=your-secret-key-change-in-production-use-long-random-string

# CORS Origins (Add your frontend URLs)
# Development: localhost URLs
# Production: Add your deployed frontend URLs
ALLOWED_ORIGINS=["http://localhost:3000","http://localhost:4000","https://lumilens.ai","https://*.vercel.app"]

# Database Paths
# Development: Local paths
# Production: Adjust for your deployment platform
CHROMA_PATH=./chroma_db  # Use /tmp/chroma_db for Vercel/serverless
DATA_PATH=./data         # Use /tmp/data for Vercel/serverless

# OpenAI Model Configuration (Optional)
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# Document Processing Settings
CHUNK_SIZE=300
CHUNK_OVERLAP=100
MAX_FILE_SIZE=52428800   # 50MB in bytes

# Rate Limiting (Optional)  
RATE_LIMIT_REQUESTS=100  # Requests per window
RATE_LIMIT_WINDOW=3600   # Window in seconds (1 hour)

# CORS Origins (Add your domains)
ALLOWED_ORIGINS=["http://localhost:3000","http://localhost:4000","https://lumilens.ai","https://*.vercel.app"]

# Database Paths
CHROMA_PATH=./chroma_db
DATA_PATH=./data

# Optional: OpenAI Model Configuration
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# Document Processing
CHUNK_SIZE=300
CHUNK_OVERLAP=100
MAX_FILE_SIZE=52428800
